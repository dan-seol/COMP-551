{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "MAX_FEATURES = 10000\n",
    "SAVE_VOCAB_FILE = 1\n",
    "SAVE_DATA_FILE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import datasets\n",
    "yelp_train = pd.read_csv(\"datasets/raw/yelp-train.txt\", sep='\\t', lineterminator='\\n', header=None, names=['review', 'label'])\n",
    "yelp_valid = pd.read_csv(\"datasets/raw/yelp-valid.txt\", sep='\\t', lineterminator='\\n', header=None, names=['review', 'label'])\n",
    "yelp_test = pd.read_csv(\"datasets/raw/yelp-test.txt\", sep='\\t', lineterminator='\\n', header=None, names=['review', 'label'])\n",
    "IMDB_train = pd.read_csv(\"datasets/raw/IMDB-train.txt\", sep='\\t', lineterminator='\\n', header=None, names=['review', 'label'])\n",
    "IMDB_valid = pd.read_csv(\"datasets/raw/IMDB-valid.txt\", sep='\\t', lineterminator='\\n', header=None, names=['review', 'label'])\n",
    "IMDB_test = pd.read_csv(\"datasets/raw/IMDB-test.txt\", sep='\\t', lineterminator='\\n', header=None, names=['review', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorize datasets\n",
    "datasets = {\n",
    "    'yelp': {'train': yelp_train, 'valid': yelp_valid, 'test': yelp_test},\n",
    "    'IMDB': {'train': IMDB_train, 'valid': IMDB_valid, 'test': IMDB_test},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp train size: 7000\n",
      "yelp valid size: 1000\n",
      "yelp test size: 2000\n",
      "IMDB train size: 15000\n",
      "IMDB valid size: 10000\n",
      "IMDB test size: 25000\n"
     ]
    }
   ],
   "source": [
    "# check dataset sizes\n",
    "for group_name, group in datasets.items():\n",
    "    for dataset_name, dataset in group.items():\n",
    "        print(group_name, dataset_name, 'size:', dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp train:\n",
      "                                              review  label\n",
      "0  I can't believe I haven't yelped about the pla...      5\n",
      "1  Best nights to go to Postino's are Mondays and...      5\n",
      "2  Went here tonight with the padres and husband....      5\n",
      "3  I must be spoiled and realize that this is not...      3\n",
      "4  Normally, love this store & have been a member...      2 \n",
      "\n",
      "IMDB train:\n",
      "                                              review  label\n",
      "0  For a movie that gets no respect there sure ar...      1\n",
      "1  Bizarre horror movie filled with famous faces ...      1\n",
      "2  A solid, if unremarkable film. Matthau, as Ein...      1\n",
      "3  It's a strange feeling to sit alone in a theat...      1\n",
      "4  You probably all already know this by now, but...      1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check dataset contents\n",
    "for group_name, group in datasets.items():\n",
    "    print(group_name, 'train:')\n",
    "    print(group['train'].head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# strip all non-word, non-space characters, <br /> tags\n",
    "for group in datasets.values():\n",
    "    for dataset in group.values():\n",
    "        dataset['review'] = dataset['review'].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp train:\n",
      "                                              review  label\n",
      "0  i cant believe i havent yelped about the place...      5\n",
      "1  best nights to go to postinos are mondays and ...      5\n",
      "2  went here tonight with the padres and husband ...      5\n",
      "3  i must be spoiled and realize that this is not...      3\n",
      "4  normally love this store  have been a member f...      2 \n",
      "\n",
      "IMDB train:\n",
      "                                              review  label\n",
      "0  for a movie that gets no respect there sure ar...      1\n",
      "1  bizarre horror movie filled with famous faces ...      1\n",
      "2  a solid if unremarkable film matthau as einste...      1\n",
      "3  its a strange feeling to sit alone in a theate...      1\n",
      "4  you probably all already know this by now but ...      1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check dataset contents\n",
    "for group_name, group in datasets.items():\n",
    "    print(group_name, 'train:')\n",
    "    print(group['train'].head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for group_name, group in datasets.items():\n",
    "    list_all_words = [word for sentence in group['train']['review'].str.split().tolist() for word in sentence]\n",
    "    list_freq_words = Counter(list_all_words).most_common(MAX_FEATURES)\n",
    "    vocab[group_name] = {word[0]: i for i, word in enumerate(list_freq_words)}\n",
    "    # save \"-vocab.txt\" file\n",
    "    if SAVE_VOCAB_FILE:\n",
    "        file_vocab = pd.DataFrame(list_freq_words)\n",
    "        file_vocab[2] = np.arange(0, MAX_FEATURES) # word IDs\n",
    "        file_vocab.to_csv('./datasets/' + group_name + '-vocab.txt', sep='\\t', header=False, index=False, columns=[0, 2, 1])\n",
    "    # save \"-train.txt\", \"-valid.txt\", \"-test.txt\" file\n",
    "    if SAVE_DATA_FILE:\n",
    "        for dataset_name, dataset in group.items():\n",
    "            with open('./datasets/' + group_name + '-' + dataset_name + '.txt', 'w') as file:\n",
    "                for i in range(len(dataset)):\n",
    "                    file.write(' '.join([str(vocab[group_name][word]) for word in dataset.iloc[i, 0].split() if word in vocab[group_name]]) \n",
    "                               + '\\t' + str(dataset.iloc[i, 1]) + '\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to BoW representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
