{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import random\n",
    "import math\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21)\n",
      "(800, 21)\n",
      "(2400, 21)\n"
     ]
    }
   ],
   "source": [
    "test = np.genfromtxt('DS2_test.csv', delimiter = ',')\n",
    "valid = np.genfromtxt('DS2_valid.csv', delimiter = ',')\n",
    "train = np.genfromtxt('DS2_train.csv', delimiter = ',')\n",
    "print(np.shape(test))\n",
    "print(np.shape(valid))\n",
    "print(np.shape(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03536196 -0.01068875 -0.00038642 -0.00916522 -0.06555391 -0.01634108\n",
      "  0.04971012  0.02155161 -0.04725721 -0.01966905 -0.02844503 -0.06206904\n",
      " -0.00700645 -0.04527776  0.07074852 -0.00875106  0.05179928 -0.04166657\n",
      "  0.05683159 -0.00696062]\n",
      "0.0932302347357511\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def countsPropMu(train, classes):\n",
    "    c = 0;\n",
    "    mu = 0;\n",
    "    \n",
    "    for row in train:\n",
    "        if row[-1] == classes:\n",
    "            c += 1\n",
    "            mu += row[:-1]\n",
    "    mu /= c\n",
    "    p = c/len(train)\n",
    "    \n",
    "    return c, p, mu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Solve for formula \\Sigma = \\sum_{i=1}^2 s_i *p_i\n",
    "#where p_i = \\frac{N_i}{N}\n",
    "#and s_i = N_i^{-1}\\sum\\{(x -\\mu_i)(x-\\mu_i)^T\\}\n",
    "def get_sigma(train, label, c, μ):\n",
    "    x = 0\n",
    "    sigma = 0\n",
    "    for row in train:\n",
    "        if row[-1] == label:\n",
    "            x = np.reshape((np.array(row[:-1])-μ),(20,1))    \n",
    "           \n",
    "            sigma += x@x.T\n",
    "    sigma /= c\n",
    "\n",
    "    return sigma\n",
    "\n",
    "def get_Cov(p0, p1, s0, s1):\n",
    "    Sigma = p0*s0 + p1*s1\n",
    "    return Sigma\n",
    "\n",
    "\n",
    "\n",
    "#Now plug in the values obtained from our data\n",
    "\n",
    "c0, p0, mu0 = countsPropMu(train, 0)\n",
    "c1, p1, mu1 = countsPropMu(train, 1)\n",
    "\n",
    "Sigma = get_Cov(p0, p1, get_sigma(train, 0, c0, mu0), get_sigma(train, 1, c1, mu1))\n",
    "\n",
    "#We will get our respective coefficient vector and bias \\beta and \\beta_0 \n",
    "#for the linear predictor \\beta^t x  + \\beta_0\n",
    "#\\beta = Sigma^{-1} (mu0-mu1)\n",
    "#\\beta_0 = \\frac{-1}{2}mu0^T Sigma^{-1} mu0 + \\frac{1}{2} mu_1^T Sigma^{-1}mu1 + ln(\\frac{P(C0)}{P(C1)})\n",
    "#Where P(C0) and P(C1) are modeled by the proportions we found\n",
    "def get_Betas(Sigma, mu0, mu1):\n",
    "    SigmaInv = np.linalg.inv(Sigma)\n",
    "    Beta = SigmaInv@(mu1-mu0)\n",
    "    Beta0 = -0.5*(mu1.T @ SigmaInv @ mu1) + 0.5*(mu0.T @ SigmaInv @ mu0)+ np.log(p1/p0)\n",
    "    return Beta, Beta0\n",
    "\n",
    "beta, beta0 = get_Betas(Sigma, mu0, mu1)\n",
    "print(beta)\n",
    "print(beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21)\n"
     ]
    }
   ],
   "source": [
    "#Define a sigmoid map\n",
    "\n",
    "sigmoid = lambda x: 1/(1+np.exp(-x)) \n",
    "\n",
    "#We use sigmoid(0) = 1/2 as our decision boundary\n",
    "\n",
    "def predClass(row, beta, beta0):\n",
    "    x = np.array(row[:-1])\n",
    "    xb = beta.T@x + beta0\n",
    "    \n",
    "    obProb = np.array(sigmoid(xb))\n",
    "    \n",
    "    predClass = 0\n",
    "    \n",
    "    #if the classifier identified it correctly as 1 sigmoid (1) > 1/2\n",
    "    if obProb >= 0.5:\n",
    "        predClass = 1;\n",
    "    return predClass\n",
    "results = []\n",
    "tp = 0\n",
    "tn = 0 \n",
    "fp = 0\n",
    "fn = 0\n",
    "print(np.shape(test))\n",
    "for i in range(800):\n",
    "    tClass = test[i][-1]\n",
    "    row = test[i][:21]\n",
    "    pClass = predClass(row, beta, beta0)\n",
    "    if pClass == 1 and tClass == 1 :\n",
    "        tp += 1\n",
    "    elif pClass == 1 and tClass == 0 :\n",
    "        fp += 1\n",
    "    elif pClass == 0 and tClass == 0 :\n",
    "        tn += 1\n",
    "    else :\n",
    "        fn += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define L2 Norm\n",
    "def L2Norm(vec1, vec2):\n",
    "   \n",
    "    return math.sqrt((vec1-vec2)@(vec1-vec2))\n",
    "\n",
    "L2Norm(np.array([1,2]), np.array([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting nearest K neighbors : iteratively defined\n",
    "def class_map(x,k): #Implementation of K-NN\n",
    "    nn = []\n",
    "    for i,row in enumerate(train):\n",
    "        point = np.array(row[:-1])\n",
    "        dif = x-point\n",
    "        dist = L2Norm(dif, 0) # l2\n",
    "        \n",
    "        if len(nn)<k:\n",
    "            nn.append([dist,i]) #save the L2norm and the index of the point\n",
    "        else:\n",
    "            nn.sort(key=lambda x: x[0]) #sort our nearest neighbours based on dist\n",
    "            if dist<nn[k-1][0]: #if we are closer than the farthest neighbour we replace it with the current val\n",
    "                del nn[-1]\n",
    "                nn.append([dist,i])\n",
    "       \n",
    "    mean = 0\n",
    "    for n in nn:\n",
    "        i = n[1] # row in train data\n",
    "        val = train[i][-1] #grab 0,1 val of row\n",
    "        mean += val\n",
    "    mean /= k\n",
    "    \n",
    "\n",
    "    if mean<.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tp, tn, fp, fn):\n",
    "   \n",
    "    accuracy = float(tp+tn)/float(tp+fp+fn+tn)\n",
    "    precision = float(tp)/float(tp+fp)\n",
    "    recall = float(tp)/float(tp+fn)\n",
    "    f1_measure = (2*precision*recall)/(precision+recall)\n",
    "    return accuracy, precision, recall, f1_measure\n",
    "#Acc, precision, recall, f1_measure = evaluate(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model on training set had following measures:\n",
      "Accuracy would be  0.51125\n",
      "Precision would be  0.5115089514066496\n",
      "Recall would be 0.5\n",
      "F-measure would be 0.5056890012642226\n"
     ]
    }
   ],
   "source": [
    "# calculate evaluation measures for GDA\n",
    "accuracy, precision, recall, f1_measure = evaluate(tp, tn, fp, fn)\n",
    "print(\"The model on test set had following measures:\")\n",
    "print(\"Accuracy would be \", accuracy)\n",
    "print(\"Precision would be \", precision)\n",
    "print(\"Recall would be\", recall)\n",
    "print(\"F-measure would be\", f1_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Accuracy would be: 0.4775\n",
      "Precision obtained: 0.4763157894736842\n",
      "Recall is: 0.4525\n",
      "F Measure observed: 0.4641025641025641\n",
      "\n",
      "\n",
      "k: 2\n",
      "Accuracy would be: 0.4825\n",
      "Precision obtained: 0.48541666666666666\n",
      "Recall is: 0.5825\n",
      "F Measure observed: 0.5295454545454545\n",
      "\n",
      "\n",
      "k: 3\n",
      "Accuracy would be: 0.4975\n",
      "Precision obtained: 0.49774774774774777\n",
      "Recall is: 0.5525\n",
      "F Measure observed: 0.523696682464455\n",
      "\n",
      "\n",
      "k: 4\n",
      "Accuracy would be: 0.5034375\n",
      "Precision obtained: 0.5029302077783697\n",
      "Recall is: 0.59\n",
      "F Measure observed: 0.5429968363531781\n",
      "\n",
      "\n",
      "k: 5\n",
      "Accuracy would be: 0.50675\n",
      "Precision obtained: 0.5059708093763822\n",
      "Recall is: 0.572\n",
      "F Measure observed: 0.5369631541891575\n",
      "\n",
      "\n",
      "k: 6\n",
      "Accuracy would be: 0.508125\n",
      "Precision obtained: 0.5070524412296564\n",
      "Recall is: 0.5841666666666666\n",
      "F Measure observed: 0.5428848015488866\n",
      "\n",
      "\n",
      "k: 7\n",
      "Accuracy would be: 0.5076785714285714\n",
      "Precision obtained: 0.5068319034000636\n",
      "Recall is: 0.5696428571428571\n",
      "F Measure observed: 0.5364049100386749\n",
      "\n",
      "\n",
      "k: 8\n",
      "Accuracy would be: 0.50859375\n",
      "Precision obtained: 0.5075778451364013\n",
      "Recall is: 0.575625\n",
      "F Measure observed: 0.5394640503734076\n",
      "\n",
      "\n",
      "k: 9\n",
      "Accuracy would be: 0.5126388888888889\n",
      "Precision obtained: 0.51134946370666\n",
      "Recall is: 0.5694444444444444\n",
      "F Measure observed: 0.5388355894335655\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test accuracy, precision, recall, and F-measure to get the ideal k\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "total = 0\n",
    "k=2\n",
    "\n",
    "for k in range(1,10):\n",
    "    for row in valid:\n",
    "        total +=1\n",
    "        x = np.array(row[:-1])\n",
    "        true_val = row[-1]\n",
    "\n",
    "        decision = class_map(x,k)\n",
    "\n",
    "        if decision == 0:\n",
    "            if true_val == 0: #specificity\n",
    "                tn+=1\n",
    "            else: #Error Type II\n",
    "                fn+=1\n",
    "        else:\n",
    "            if true_val == 0: #Error Type I\n",
    "                fp+=1\n",
    "            else: #sensitivity\n",
    "                tp+=1\n",
    "\n",
    "\n",
    "\n",
    "    acc = (tn+tp)/total\n",
    "    prec = tp/(tp+fp) \n",
    "    rec = tp/(tp+fn)\n",
    "    f = 2*prec*rec/(prec+rec)\n",
    "\n",
    "    print(f\"k: {k}\")\n",
    "    print(f\"Accuracy would be: {acc}\")\n",
    "    print(f\"Precision obtained: {prec}\")\n",
    "    print(f\"Recall is: {rec}\")\n",
    "    print(f\"F Measure observed: {f}\")\n",
    "    print('\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2\n",
      "Accuracy would be: 0.525\n",
      "Precision obtained: 0.5165562913907285\n",
      "Recall is: 0.78\n",
      "F Measure observed: 0.6215139442231076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test accuracy, precision, recall, and F-measure to get the ideal k\n",
    "#The valid set suggests using 2 might be a good choice\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "total = 0\n",
    "k=2\n",
    "\n",
    "\n",
    "for row in test:\n",
    "    total +=1\n",
    "    x = np.array(row[:-1])\n",
    "    true_val = row[-1]\n",
    "\n",
    "    decision = class_map(x,k)\n",
    "\n",
    "    if decision == 0:\n",
    "        if true_val == 0: #specificity\n",
    "            tn+=1\n",
    "        else: #Error Type II\n",
    "            fn+=1\n",
    "    else:\n",
    "        if true_val == 0: #Error Type I\n",
    "            fp+=1\n",
    "        else: #sensitivity\n",
    "            tp+=1\n",
    "\n",
    "\n",
    "\n",
    "acc = (tn+tp)/total\n",
    "prec = tp/(tp+fp) \n",
    "rec = tp/(tp+fn)\n",
    "f = 2*prec*rec/(prec+rec)\n",
    "\n",
    "print(f\"k: {k}\")\n",
    "print(f\"Accuracy would be: {acc}\")\n",
    "print(f\"Precision obtained: {prec}\")\n",
    "print(f\"Recall is: {rec}\")\n",
    "print(f\"F Measure observed: {f}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
