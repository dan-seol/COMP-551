{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider cases where we classify input $\\textbf{x}$ in the input space $C(\\mathbf{X})$ to a class $C_k$ and we have a discriminant function (or any map) that maps $\\textbf{x}$ to a class $C_k \\in  \\{C_1, ..., C_K\\}$\n",
    "\n",
    "Evaluation metrics for classification problem:\n",
    "\n",
    " $P_{\\text{true}}:=|\\{\\mathbf{x} \\in C(\\mathbf{X}): y(\\mathbf{x}) = C_k | \\mathbf{x} \\in C_k \\}| $\n",
    "  \n",
    " $P_{\\text{false}}:=|\\{\\mathbf{x} \\in C(\\mathbf{X}): y(\\mathbf{x}) = C_k | \\mathbf{x} \\notin C_k \\}| $\n",
    " \n",
    " $N_{\\text{true}}:=|\\{\\mathbf{x} \\in C(\\mathbf{X}): y(\\mathbf{x}) \\neq C_k | \\mathbf{x} \\notin C_k \\}| $\n",
    "  \n",
    " $N_{\\text{false}}:=|\\{\\mathbf{x} \\in C(\\mathbf{X}): y(\\mathbf{x}) \\neq C_k | \\mathbf{x} \\in C_k \\}| $\n",
    " \n",
    " \n",
    " and we have total counts $\\text{TOTAL} : = P_{\\text{true}} +P_{\\text{false}} + N_{\\text{true}} + N_{\\text{false}} $\n",
    " \n",
    " Accuracy $Acc := \\frac{P_{\\text{true}} + N_{\\text{true}} }{TOTAL}$\n",
    " \n",
    " Precision $Pcs := \\frac{P_{\\text{true}}}{P_{\\text{true}}+P_{\\text{false}} }$\n",
    " \n",
    " Recall $Rec := \\frac{P_{\\text{true}}}{P_{\\text{true}}+F_{\\text{false}} }$\n",
    " \n",
    " F_1 measure $F_1 := \\frac{2*Pcs * Rec}{Pcs+Rec}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21)\n",
      "(800, 21)\n",
      "(2400, 21)\n"
     ]
    }
   ],
   "source": [
    "test = np.genfromtxt('DS1_test.csv', delimiter = ',')\n",
    "valid = np.genfromtxt('DS1_valid.csv', delimiter = ',')\n",
    "train = np.genfromtxt('DS1_train.csv', delimiter = ',')\n",
    "print(np.shape(test))\n",
    "print(np.shape(valid))\n",
    "print(np.shape(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.85992178   8.72562473   5.68227111   3.27898269   9.92186112\n",
      "   4.555445   -17.12291339  24.46050271  29.71995544  -9.3559337\n",
      "  13.30979447  12.47838008 -15.75210565 -13.07731511   5.72648095\n",
      " -13.23577877 -30.10077125   6.80408844   0.65591131   5.05253155]\n",
      "-27.81483255516115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def countsPropMu(train, classes):\n",
    "    c = 0;\n",
    "    mu = 0;\n",
    "    \n",
    "    for row in train:\n",
    "        if row[-1] == classes:\n",
    "            c += 1\n",
    "            mu += row[:-1]\n",
    "    mu /= c\n",
    "    p = c/len(train)\n",
    "    \n",
    "    return c, p, mu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Solve for formula \\Sigma = \\sum_{i=1}^2 s_i *p_i\n",
    "#where p_i = \\frac{N_i}{N}\n",
    "#and s_i = N_i^{-1}\\sum\\{(x -\\mu_i)(x-\\mu_i)^T\\}\n",
    "def get_sigma(train, label, c, μ):\n",
    "    x = 0\n",
    "    sigma = 0\n",
    "    for row in train:\n",
    "        if row[-1] == label:\n",
    "            x = np.reshape((np.array(row[:-1])-μ),(20,1))    \n",
    "           \n",
    "            sigma += x@x.T\n",
    "    sigma /= c\n",
    "\n",
    "    return sigma\n",
    "\n",
    "def get_Cov(p0, p1, s0, s1):\n",
    "    Sigma = p0*s0 + p1*s1\n",
    "    return Sigma\n",
    "\n",
    "\n",
    "\n",
    "#Now plug in the values obtained from our data\n",
    "\n",
    "c0, p0, mu0 = countsPropMu(train, 0)\n",
    "c1, p1, mu1 = countsPropMu(train, 1)\n",
    "\n",
    "Sigma = get_Cov(p0, p1, get_sigma(train, 0, c0, mu0), get_sigma(train, 1, c1, mu1))\n",
    "\n",
    "#We will get our respective coefficient vector and bias \\beta and \\beta_0 \n",
    "#for the linear predictor \\beta^t x  + \\beta_0\n",
    "#\\beta = Sigma^{-1} (mu0-mu1)\n",
    "#\\beta_0 = \\frac{-1}{2}mu0^T Sigma^{-1} mu0 + \\frac{1}{2} mu_1^T Sigma^{-1}mu1 + ln(\\frac{P(C0)}{P(C1)})\n",
    "#Where P(C0) and P(C1) are modeled by the proportions we found\n",
    "def get_Betas(Sigma, mu0, mu1):\n",
    "    SigmaInv = np.linalg.inv(Sigma)\n",
    "    Beta = SigmaInv@(mu1-mu0)\n",
    "    Beta0 = -0.5*(mu1.T @ SigmaInv @ mu1) + 0.5*(mu0.T @ SigmaInv @ mu0)+ np.log(p1/p0)\n",
    "    return Beta, Beta0\n",
    "\n",
    "beta, beta0 = get_Betas(Sigma, mu0, mu1)\n",
    "print(beta)\n",
    "print(beta0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21)\n"
     ]
    }
   ],
   "source": [
    "#Define a sigmoid map\n",
    "\n",
    "sigmoid = lambda x: 1/(1+np.exp(-x)) \n",
    "\n",
    "#We use sigmoid(0) = 1/2 as our decision boundary\n",
    "\n",
    "def predClass(row, beta, beta0):\n",
    "    x = np.array(row[:-1])\n",
    "    xb = beta.T@x + beta0\n",
    "    \n",
    "    obProb = np.array(sigmoid(xb))\n",
    "    \n",
    "    predClass = 0\n",
    "    \n",
    "    #if the classifier identified it correctly as 1 sigmoid (1) > 1/2\n",
    "    if obProb >= 0.5:\n",
    "        predClass = 1;\n",
    "    return predClass\n",
    "results = []\n",
    "tp = 0\n",
    "tn = 0 \n",
    "fp = 0\n",
    "fn = 0\n",
    "print(np.shape(test))\n",
    "for i in range(800):\n",
    "    tClass = test[i][-1]\n",
    "    row = test[i][:21]\n",
    "    pClass = predClass(row, beta, beta0)\n",
    "    if pClass == 1 and tClass == 1 :\n",
    "        tp += 1\n",
    "    elif pClass == 1 and tClass == 0 :\n",
    "        fp += 1\n",
    "    elif pClass == 0 and tClass == 0 :\n",
    "        tn += 1\n",
    "    else :\n",
    "        fn += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA returned me the result:\n",
      "Accuracy would be  0.9575\n",
      "Precision would be  0.9463414634146341\n",
      "Recall would be 0.97\n",
      "F-measure would be 0.9580246913580247\n"
     ]
    }
   ],
   "source": [
    "def evaluate(tp, tn, fp, fn):\n",
    "   \n",
    "    accuracy = float(tp+tn)/float(tp+fp+fn+tn)\n",
    "    precision = float(tp)/float(tp+fp)\n",
    "    recall = float(tp)/float(tp+fn)\n",
    "    f1_measure = (2*precision*recall)/(precision+recall)\n",
    "    return accuracy, precision, recall, f1_measure\n",
    "\n",
    "# calculate evaluation metrics\n",
    "accuracy, precision, recall, f1_measure = evaluate(tp, tn, fp, fn)\n",
    "print(\"LDA returned me the result:\")\n",
    "print(\"Accuracy would be \", accuracy)\n",
    "print(\"Precision would be \", precision)\n",
    "print(\"Recall would be\", recall)\n",
    "print(\"F-measure would be\", f1_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
